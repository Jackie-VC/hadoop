[cloudera@quickstart hadoop]$ hadoop jar /home/cloudera/git/hadoop/target/hadoop-1.0-SNAPSHOT.jar  org.myorg.AverageInMapper /user/cloudera/AverageInMapper/input /user/cloudera/AverageInMapper/output
18/01/31 12:32:48 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
18/01/31 12:32:49 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
18/01/31 12:32:50 INFO input.FileInputFormat: Total input paths to process : 1
18/01/31 12:32:51 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1281)
	at java.lang.Thread.join(Thread.java:1355)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:952)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:690)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:879)
18/01/31 12:32:51 INFO mapreduce.JobSubmitter: number of splits:1
18/01/31 12:32:51 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1517258179611_0011
18/01/31 12:32:53 INFO impl.YarnClientImpl: Submitted application application_1517258179611_0011
18/01/31 12:32:53 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1517258179611_0011/
18/01/31 12:32:53 INFO mapreduce.Job: Running job: job_1517258179611_0011
18/01/31 12:33:14 INFO mapreduce.Job: Job job_1517258179611_0011 running in uber mode : false
18/01/31 12:33:14 INFO mapreduce.Job:  map 0% reduce 0%
18/01/31 12:33:34 INFO mapreduce.Job:  map 100% reduce 0%
18/01/31 12:33:54 INFO mapreduce.Job:  map 100% reduce 100%
18/01/31 12:33:54 INFO mapreduce.Job: Job job_1517258179611_0011 completed successfully
18/01/31 12:33:55 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=29380
		FILE: Number of bytes written=309309
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=174592
		HDFS: Number of bytes written=15
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=17602
		Total time spent by all reduces in occupied slots (ms)=17040
		Total time spent by all map tasks (ms)=17602
		Total time spent by all reduce tasks (ms)=17040
		Total vcore-milliseconds taken by all map tasks=17602
		Total vcore-milliseconds taken by all reduce tasks=17040
		Total megabyte-milliseconds taken by all map tasks=18024448
		Total megabyte-milliseconds taken by all reduce tasks=17448960
	Map-Reduce Framework
		Map input records=1546
		Map output records=1546
		Map output bytes=26282
		Map output materialized bytes=29380
		Input split bytes=143
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=29380
		Reduce input records=1546
		Reduce output records=1
		Spilled Records=3092
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=497
		CPU time spent (ms)=3150
		Physical memory (bytes) snapshot=334639104
		Virtual memory (bytes) snapshot=3016572928
		Total committed heap usage (bytes)=226365440
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=174449
	File Output Format Counters 
		Bytes Written=15
